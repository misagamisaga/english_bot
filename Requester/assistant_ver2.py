import warnings
warnings.filterwarnings("ignore")

import os
import streamlit as st
import random
# import requests
# import re

# from langchain.llms import OpenAI
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

from langchain_openai import ChatOpenAI
# from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate


# ---- å‡†å¤‡å·¥ä½œ ----
os.environ["OPENAI_API_BASE"] = "https://api.chatanywhere.tech/v1"

template_evaluate = """
You are a very skilled English teacher. Now you need to evaluate the student's performance in English conversation. Please guide this user to engage in English conversation and test their English language ability.  

The evaluation section needs to consist of three parts. When the other party provides an English answer, please primarily evaluate in Chinese.  
1. Rate the other party's response on a scale of 0-10 points, with 0 indicating poor response and 10 indicating excellent response.  
2. Check if there are any grammar or vocabulary errors in the other party's answer. If so, please point out the errors and provide suggestions for correction.  
3. Provide an example to demonstrate the correct English expression and explain why it is better to say it that way.  

Please note that the correct demonstration sentence you provide must be in English.

Chat history:{chat_history}

Answer from the student:{user_question}
"""

template_conversation = """
You are a very skilled English teacher. Now you need to practice English with a student through conversation. Please guide this user to engage in English conversation and test their English language ability.  

Based on the history of the conversation, continue the English conversation, guide him to speak more English, and try to test his English language ability as much as possible.  

Chat history:{chat_history}

Answer from the student:{user_question}
"""

# æ”¹ä¸ºé›…æ€é¢˜åº“
text_list_yasi = [
    "Are there many advertisements in your country?", 
    "Why do you think there are so many advertisements in your country now?", 
    "What are the various places where we see advertisements?", 
    "How do you feel about advertisements?", 
    "How do children celebrate birthdays in your country?", 
    "How did you celebrate your last birthday?", 
    "What kind of birthday gift did you like toreceive?", 
    "Is there a difference between the way you celebrated your birthday in the past and in the present?", 
    "Do you like flowers?", 
    "What flowers do you like?", 
    "Which/What is your favorite flower?", 
    "Do you think flowers are importnat?", 
    "Are flowers important in your culture?", 
    "On what occasions are flowers important?", 
    "Do people in your country ever use flowers for special occasions?", 
    "In your country, do people give flowers as a gift?", 
    "What are the occasions when people give or receive flowers?", 
]
text_start = "The IELTS exam has officially begun, and AI assistants will act as examiners to ask initial questions and assess students' English proficiency through chat. Please have students engage in a dialogue based on the examiner's questions."

# ---- é¡µé¢å†…å®¹ ----

# è®¾ç½®æœ¬é¡µåœ¨ä¾§è¾¹æ ä¸­çš„åç§°å’Œå›¾æ ‡
# st.set_page_config("AIè‹±è¯­é™ªç»ƒ", "ğŸ¤–")

col1, col2 = st.columns([2, 1])
with col1:
    # é¡µé¢å¤´éƒ¨çš„ä¸œè¥¿
    st.title("AIè‹±è¯­é›…æ€é™ªç»ƒ")

with col2:
    st.markdown("\n")
    if_clean = st.button("æ–°å¯¹è¯")

if if_clean:
    # st.cache_data.clear()
    # st.cache_resource.clear()
    st.session_state.chat_history = [
        SystemMessage(content=text_start), 
        AIMessage(content=random.choice(text_list_yasi))
    ]

st.markdown("""> æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨è¯•ç”¨æˆ‘ã€‚ç”±äºæ¨¡å‹è¿˜åœ¨å¼€å‘é˜¶æ®µï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½éœ€è¦æ‚¨æ³¨æ„: 
> * **è¯·ç­‰å¾…æ¨¡å‹å›ç­”å®Œæ¯•åå†æé—®ä¸‹ä¸€ä¸ªé—®é¢˜ï¼Œä»¥é˜²æ­¢å›ç­”å†…å®¹è¢«è¦†ç›–ã€‚** 
> * **ç›®å‰æ¨¡å‹çš„å›ç­”è´¨é‡è¿˜ä¸é”™ï¼Œä½†ä»ç„¶å¤„äºå¼€å‘é˜¶æ®µï¼Œååº”è¾ƒæ…¢ï¼Œä¸”å›ç­”å¯èƒ½æœ‰æ‰€åå·®ã€‚** è¯·æ‚¨è°…è§£ï¼Œæˆ‘ä»¬ä¼šæŒç»­æ”¹è¿›æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¹¶ä¸”å¾ˆä¹æ„æ”¶åˆ°æ‚¨çš„åé¦ˆã€‚
---
""")

api_in = st.text_input(label="è¯·è¾“å…¥æ‚¨çš„api-key")

# åˆå§‹åŒ–é¡µé¢çš„æ—¶å€™è®©AIæ˜¾ç¤ºä¸€æ¡æ¬¢è¿è¯­ï¼Œå¹¶å­˜å…¥messages
if "chat_history" not in st.session_state:
    st.cache_data.clear()
    st.cache_resource.clear()
    st.session_state.chat_history = [
        SystemMessage(content=text_start), 
        AIMessage(content=random.choice(text_list_yasi))
    ]

# conversation
for message in st.session_state.chat_history:
    if isinstance(message, AIMessage):
        with st.chat_message("AI"):
            st.write(message.content)
    elif isinstance(message, HumanMessage):
        with st.chat_message("Human"):
            st.write(message.content)

# def get_response_chat(user_query, chat_history):
#     prompt = ChatPromptTemplate.from_template(template_conversation)
#     llm = ChatOpenAI(model="gpt-4")
#     chain = prompt | llm | StrOutputParser()
#     return chain.stream({
#         "chat_history": chat_history,
#         "user_question": user_query,
#     })

# def get_response_eval(user_query, chat_history):
#     prompt = ChatPromptTemplate.from_template(template_evaluate)
#     llm = ChatOpenAI(model="gpt-4")
#     chain = prompt | llm | StrOutputParser()
#     return chain.stream({
#         "chat_history": chat_history,
#         "user_question": user_query,
#     })

# ç­‰å¾…ç”¨æˆ·è¾“å…¥ç„¶åæŒ‰å›è½¦
if ques_user := st.chat_input("ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ ï¼Ÿ"):

    llm = ChatOpenAI(model="gpt-4o-2024-08-06", api_key=api_in)
    
    # åœ¨messagesé‡Œé¢å­˜å…¥ç”¨æˆ·çš„æ¶ˆæ¯
    st.session_state.chat_history.append(HumanMessage(content=ques_user))

    # åœ¨messagesé‡Œé¢æ˜¾ç¤ºç”¨æˆ·çš„å›ç­”
    with st.chat_message("Human"):
        st.markdown(ques_user)

    # åœ¨messagesé‡Œé¢æµå¼æ˜¾ç¤ºAIçš„å›ç­”
    with st.chat_message("AI"):
        # response = st.write_stream(get_response_chat(ques_user, st.session_state.chat_history))
        prompt_chat = ChatPromptTemplate.from_template(template_conversation)
        chain_chat = prompt_chat | llm | StrOutputParser()
        response = st.write_stream(chain_chat.stream({
            "chat_history": st.session_state.chat_history,
            "user_question": ques_user,
        }))
    
    # åœ¨messagesé‡Œé¢å­˜å…¥æœ¬æ¬¡AIçš„å›ç­”
    st.session_state.chat_history.append(AIMessage(content=response))

    # ----- è¯„ä¼°éƒ¨åˆ† -----
    prompt_eval = ChatPromptTemplate.from_template(template_evaluate)
    chain_eval = prompt_eval | llm | StrOutputParser()

    with st.sidebar:
        st.markdown("### æœ¬æ¬¡é—®ç­”è¯„ä»·ï¼š")
        st.write_stream(chain_eval.stream({
            "chat_history": st.session_state.chat_history,
            "user_question": ques_user,
        }))
